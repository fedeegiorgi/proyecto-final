{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.io import arff\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import lognorm\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED = 14208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filepath = 'datasets/boston_housing.arff'  # Aquí se incluirían las rutas a los datasets\n",
    "pred_col_name = 'MEDV'  # Columna a predecir\n",
    "alpha = 0.1  # Nivel de significancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_filepath: str, pred_col_name: str):\n",
    "    # Obtener la extension del archivo\n",
    "    _, file_extension = os.path.splitext(dataset_filepath)\n",
    "\n",
    "    # Cargar el dataset según la extensión\n",
    "    if file_extension == '.arff':\n",
    "        data = arff.loadarff(dataset_filepath)\n",
    "        df = pd.DataFrame(data[0])\n",
    "\n",
    "    elif file_extension == '.csv':\n",
    "        df = pd.read_csv(dataset_filepath)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Formato no soportado, `dataset_filepath` debe tener una de las siguientes extensiones: .csv, .arff\")\n",
    "\n",
    "    # Separar el dataset en Train y Validation\n",
    "    train_df, validation_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "    y_train, y_valid = train_df[pred_col_name], validation_df[pred_col_name]\n",
    "    X_train, X_valid = train_df.drop(pred_col_name, axis=1), validation_df.drop(pred_col_name, axis=1)\n",
    "\n",
    "    # Aplicar get_dummies para variables categóricas\n",
    "    X_train = pd.get_dummies(X_train)\n",
    "    X_valid = pd.get_dummies(X_valid)\n",
    "    X_train, X_valid = X_train.align(X_valid, join='left', axis=1, fill_value=0) \n",
    "\n",
    "    # Crear y entrenar el modelo de Random Forest\n",
    "    rf_model = RandomForestRegressor(random_state=SEED)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones de cada árbol en el bosque\n",
    "    tree_predictions = []\n",
    "    for tree in rf_model.estimators_:\n",
    "        tree_pred = tree.predict(X_valid)\n",
    "        tree_predictions.append(tree_pred)\n",
    "\n",
    "    tree_predictions = np.array(tree_predictions).T\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    predictions = rf_model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, predictions)\n",
    "\n",
    "    return df, mse, predictions, tree_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lognormal_KS_fit_check(tree_predictions, shift=1e-6, alpha=0.05, orig_data_stat=0.0722):\n",
    "    ks_results = []\n",
    "    tree_predictions += shift\n",
    "    for predictions in tree_predictions:\n",
    "        # Estimate parameters of the lognormal distribution\n",
    "        shape, loc, scale = stats.lognorm.fit(predictions, floc=0)\n",
    "        \n",
    "        # Perform the Kolmogorov-Smirnov test\n",
    "        ks_stat, p_value = stats.kstest(predictions, 'lognorm', args=(shape, loc, scale))\n",
    "        ks_results.append((ks_stat, p_value, shape, loc, scale))\n",
    "\n",
    "    # Proportion of trees that fit the lognormal distribution\n",
    "    ks_stats = [result[0] for result in ks_results]\n",
    "    eps = alpha * orig_data_stat\n",
    "    filtered_stats = [stat for stat in ks_stats if orig_data_stat-eps <= stat <= orig_data_stat+eps]\n",
    "    ks_fit_proportion = len(filtered_stats) / len(ks_stats)\n",
    "    \n",
    "    return ks_fit_proportion, ks_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_KS_fit_check(tree_predictions, shift=1e-6, alpha=0.05, orig_data_stat=0.1323):\n",
    "    ks_results = []\n",
    "    tree_predictions += shift\n",
    "    for predictions in tree_predictions:\n",
    "        # Estimate parameters of the lognormal distribution\n",
    "        shape, loc, scale = stats.gamma.fit(predictions, floc=0)\n",
    "        \n",
    "        # Perform the Kolmogorov-Smirnov test\n",
    "        ks_stat, p_value = stats.kstest(predictions, 'gamma', args=(shape, loc, scale))\n",
    "        ks_results.append((ks_stat, p_value, shape, loc, scale))\n",
    "\n",
    "    # Proportion of trees that fit the lognormal distribution\n",
    "    ks_stats = [result[0] for result in ks_results]\n",
    "    eps = alpha * orig_data_stat\n",
    "    filtered_stats = [stat for stat in ks_stats if orig_data_stat-eps <= stat <= orig_data_stat+eps]\n",
    "    ks_fit_proportion = len(filtered_stats) / len(ks_stats)\n",
    "    \n",
    "    return ks_fit_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforme_normal_SW_fit_check(tree_predictions, shift=1e-6, alpha=0.05, orig_data_stat=0.9809):\n",
    "    sw_results = []\n",
    "    tree_predictions = np.log1p(tree_predictions)\n",
    "\n",
    "    for predictions in tree_predictions:\n",
    "        # Perform the Shapiro-Wilk test\n",
    "        shapiro_stat, shapiro_p_value = stats.shapiro(predictions)\n",
    "        sw_results.append((shapiro_stat, shapiro_p_value))\n",
    "\n",
    "    # Proportion of trees that fit the normal distribution\n",
    "    sw_stats = [result[0] for result in sw_results]\n",
    "    eps = alpha * orig_data_stat\n",
    "    filtered_stats = [stat for stat in sw_stats if orig_data_stat-eps <= stat <= orig_data_stat+eps]\n",
    "    sw_fit_proportion = len(filtered_stats) / len(sw_stats)\n",
    "    \n",
    "    return sw_fit_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_lognormal_fit(predictions, dataset_name, save=False, shift=1e-6, given_index=0):\n",
    "#     predictions = predictions[given_index]\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(predictions, kde=True, stat='density', bins=30, color='green', alpha=0.6 , label='Data')\n",
    "\n",
    "#     shape, loc, scale = stats.lognorm.fit(predictions, floc=0)\n",
    "\n",
    "#     x = np.linspace(min(predictions), max(predictions), 100)\n",
    "#     pdf_lognormal = stats.lognorm.pdf(x, shape, loc, scale)\n",
    "#     plt.plot(x, pdf_lognormal, 'r-', label='Lognormal Distribution')\n",
    "\n",
    "#     plt.title(f\"Distribucion de las predicciones | Instancia {given_index} [Validation Set]\")\n",
    "#     plt.legend()\n",
    "\n",
    "#     if save:\n",
    "#         plt.savefig(f'graficos/predictions/{dataset_name}/distribution_lognormal/{i}.png', format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_normal_fit(predictions, dataset_name, save=False, shift=1e-6, given_index=0):\n",
    "#     predictions = predictions[given_index]\n",
    "#     predictions = np.log1p(predictions)\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.histplot(predictions, kde=True, stat='density', bins=30, color='green', alpha=0.6 , label='Transformed Data')\n",
    "\n",
    "#     mean, std = np.mean(predictions), np.std(predictions)\n",
    "\n",
    "#     x = np.linspace(min(predictions), max(predictions), 100)\n",
    "#     pdf_normal = stats.norm.pdf(x, mean, std)\n",
    "#     plt.plot(x, pdf_normal, 'r-', label='Normal Distribution')\n",
    "\n",
    "#     plt.title(f\"Distribucion de las predicciones | Instancia {given_index} [Validation Set]\")\n",
    "#     plt.legend()\n",
    "\n",
    "#     if save:\n",
    "#         plt.savefig(f'graficos/predictions/{dataset_name}/distribution_normal/{i}.png', format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of trees that fit the lognormal distribution: 0.00980\n",
      "Proportion of trees that fit the normal distribution (over transformed data): 0.59804\n"
     ]
    }
   ],
   "source": [
    "dataset_titanic, mse_titanic, predictions_titanic, tree_predictions_titanic = process_dataset(dataset_filepath, pred_col_name)\n",
    "\n",
    "ks_lognormal_fit_proportion, ks_stats = lognormal_KS_fit_check(tree_predictions_titanic, alpha=alpha)\n",
    "print(f\"Proportion of trees that fit the lognormal distribution: {ks_lognormal_fit_proportion:.5f}\")\n",
    "\n",
    "sw_fit_proportion = transforme_normal_SW_fit_check(tree_predictions_titanic, alpha=alpha)\n",
    "print(f\"Proportion of trees that fit the normal distribution (over transformed data): {sw_fit_proportion:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = os.path.basename(dataset_filepath)\n",
    "file_path = 'datasets_results.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Open the file\n",
    "    df = pd.read_csv(file_path)\n",
    "else:\n",
    "    # Create a new dataframe with column headers\n",
    "    df = pd.DataFrame(columns=['dataset_name', 'prop_lognormal', 'prop_normal', 'alpha', 'pred_col_name'])\n",
    "\n",
    "# Add a new row with values\n",
    "new_row = {'dataset_name': dataset_name, 'prop_lognormal': ks_lognormal_fit_proportion, 'prop_normal': sw_fit_proportion, 'alpha': alpha, 'pred_col_name': pred_col_name}\n",
    "df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "# Save the dataframe to the file\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>prop_lognormal</th>\n",
       "      <th>prop_normal</th>\n",
       "      <th>alpha</th>\n",
       "      <th>pred_col_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>titanic_fare_test.arff</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.206107</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medical_costs.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.05</td>\n",
       "      <td>medical charges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salary_football.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Wage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight_price.csv</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.038372</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Height.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080214</td>\n",
       "      <td>0.05</td>\n",
       "      <td>childHeight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine_quality.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.05</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>house_8L.arff</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.482115</td>\n",
       "      <td>0.05</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>titanic_fare_test.arff</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>medical_costs.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078358</td>\n",
       "      <td>0.10</td>\n",
       "      <td>medical charges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>salary_football.csv</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.485934</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Wage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Height.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417112</td>\n",
       "      <td>0.10</td>\n",
       "      <td>childHeight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wine_quality.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033846</td>\n",
       "      <td>0.10</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>house_8L.arff</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>0.695414</td>\n",
       "      <td>0.10</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kidney.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>frailty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kidney.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>frailty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>flight_price.csv</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.106692</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>boston_housing.arff</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>MEDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>boston_housing.arff</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.10</td>\n",
       "      <td>MEDV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset_name  prop_lognormal  prop_normal  alpha  \\\n",
       "0   titanic_fare_test.arff        0.003817     0.206107   0.05   \n",
       "1        medical_costs.csv        0.000000     0.007463   0.05   \n",
       "2      salary_football.csv        0.000000     0.223785   0.05   \n",
       "3         flight_price.csv        0.000468     0.038372   0.05   \n",
       "4               Height.csv        0.000000     0.080214   0.05   \n",
       "5        wine_quality.arff        0.000000     0.005385   0.05   \n",
       "6            house_8L.arff        0.023261     0.482115   0.05   \n",
       "7   titanic_fare_test.arff        0.019084     0.381679   0.10   \n",
       "8        medical_costs.csv        0.000000     0.078358   0.10   \n",
       "9      salary_football.csv        0.002558     0.485934   0.10   \n",
       "10              Height.csv        0.000000     0.417112   0.10   \n",
       "11       wine_quality.arff        0.000000     0.033846   0.10   \n",
       "12           house_8L.arff        0.043889     0.695414   0.10   \n",
       "13             kidney.arff        0.000000     0.000000   0.05   \n",
       "14             kidney.arff        0.000000     0.250000   0.10   \n",
       "15        flight_price.csv        0.000468     0.106692   0.10   \n",
       "16     boston_housing.arff        0.009804     0.313725   0.05   \n",
       "17     boston_housing.arff        0.009804     0.598039   0.10   \n",
       "\n",
       "      pred_col_name  \n",
       "0              Fare  \n",
       "1   medical charges  \n",
       "2              Wage  \n",
       "3             Price  \n",
       "4       childHeight  \n",
       "5           quality  \n",
       "6             price  \n",
       "7              Fare  \n",
       "8   medical charges  \n",
       "9              Wage  \n",
       "10      childHeight  \n",
       "11          quality  \n",
       "12            price  \n",
       "13          frailty  \n",
       "14          frailty  \n",
       "15            Price  \n",
       "16             MEDV  \n",
       "17             MEDV  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>prop_lognormal</th>\n",
       "      <th>prop_normal</th>\n",
       "      <th>alpha</th>\n",
       "      <th>pred_col_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>house_8L.arff</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>0.695414</td>\n",
       "      <td>0.10</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>boston_housing.arff</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.10</td>\n",
       "      <td>MEDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>salary_football.csv</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.485934</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Wage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>house_8L.arff</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.482115</td>\n",
       "      <td>0.05</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Height.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.417112</td>\n",
       "      <td>0.10</td>\n",
       "      <td>childHeight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>titanic_fare_test.arff</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>boston_housing.arff</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>MEDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kidney.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>frailty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>salary_football.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223785</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Wage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>titanic_fare_test.arff</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.206107</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>flight_price.csv</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.106692</td>\n",
       "      <td>0.10</td>\n",
       "      <td>Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Height.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080214</td>\n",
       "      <td>0.05</td>\n",
       "      <td>childHeight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>medical_costs.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078358</td>\n",
       "      <td>0.10</td>\n",
       "      <td>medical charges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight_price.csv</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.038372</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wine_quality.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033846</td>\n",
       "      <td>0.10</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medical_costs.csv</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.05</td>\n",
       "      <td>medical charges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wine_quality.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.05</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kidney.arff</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>frailty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset_name  prop_lognormal  prop_normal  alpha  \\\n",
       "12           house_8L.arff        0.043889     0.695414   0.10   \n",
       "17     boston_housing.arff        0.009804     0.598039   0.10   \n",
       "9      salary_football.csv        0.002558     0.485934   0.10   \n",
       "6            house_8L.arff        0.023261     0.482115   0.05   \n",
       "10              Height.csv        0.000000     0.417112   0.10   \n",
       "7   titanic_fare_test.arff        0.019084     0.381679   0.10   \n",
       "16     boston_housing.arff        0.009804     0.313725   0.05   \n",
       "14             kidney.arff        0.000000     0.250000   0.10   \n",
       "2      salary_football.csv        0.000000     0.223785   0.05   \n",
       "0   titanic_fare_test.arff        0.003817     0.206107   0.05   \n",
       "15        flight_price.csv        0.000468     0.106692   0.10   \n",
       "4               Height.csv        0.000000     0.080214   0.05   \n",
       "8        medical_costs.csv        0.000000     0.078358   0.10   \n",
       "3         flight_price.csv        0.000468     0.038372   0.05   \n",
       "11       wine_quality.arff        0.000000     0.033846   0.10   \n",
       "1        medical_costs.csv        0.000000     0.007463   0.05   \n",
       "5        wine_quality.arff        0.000000     0.005385   0.05   \n",
       "13             kidney.arff        0.000000     0.000000   0.05   \n",
       "\n",
       "      pred_col_name  \n",
       "12            price  \n",
       "17             MEDV  \n",
       "9              Wage  \n",
       "6             price  \n",
       "10      childHeight  \n",
       "7              Fare  \n",
       "16             MEDV  \n",
       "14          frailty  \n",
       "2              Wage  \n",
       "0              Fare  \n",
       "15            Price  \n",
       "4       childHeight  \n",
       "8   medical charges  \n",
       "3             Price  \n",
       "11          quality  \n",
       "1   medical charges  \n",
       "5           quality  \n",
       "13          frailty  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='prop_normal', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "td6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
